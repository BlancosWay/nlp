\documentclass[11pt]{article}\usepackage{graphicx, color}
%% maxwidth is the original width if it is less than linewidth
%% otherwise use linewidth (to make sure the graphics do not exceed the margin)
\makeatletter
\def\maxwidth{ %
  \ifdim\Gin@nat@width>\linewidth
    \linewidth
  \else
    \Gin@nat@width
  \fi
}
\makeatother

\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\definecolor{fgcolor}{rgb}{0.2, 0.2, 0.2}
\newcommand{\hlnumber}[1]{\textcolor[rgb]{0,0,0}{#1}}%
\newcommand{\hlfunctioncall}[1]{\textcolor[rgb]{0.501960784313725,0,0.329411764705882}{\textbf{#1}}}%
\newcommand{\hlstring}[1]{\textcolor[rgb]{0.6,0.6,1}{#1}}%
\newcommand{\hlkeyword}[1]{\textcolor[rgb]{0,0,0}{\textbf{#1}}}%
\newcommand{\hlargument}[1]{\textcolor[rgb]{0.690196078431373,0.250980392156863,0.0196078431372549}{#1}}%
\newcommand{\hlcomment}[1]{\textcolor[rgb]{0.180392156862745,0.6,0.341176470588235}{#1}}%
\newcommand{\hlroxygencomment}[1]{\textcolor[rgb]{0.43921568627451,0.47843137254902,0.701960784313725}{#1}}%
\newcommand{\hlformalargs}[1]{\textcolor[rgb]{0.690196078431373,0.250980392156863,0.0196078431372549}{#1}}%
\newcommand{\hleqformalargs}[1]{\textcolor[rgb]{0.690196078431373,0.250980392156863,0.0196078431372549}{#1}}%
\newcommand{\hlassignement}[1]{\textcolor[rgb]{0,0,0}{\textbf{#1}}}%
\newcommand{\hlpackage}[1]{\textcolor[rgb]{0.588235294117647,0.709803921568627,0.145098039215686}{#1}}%
\newcommand{\hlslot}[1]{\textit{#1}}%
\newcommand{\hlsymbol}[1]{\textcolor[rgb]{0,0,0}{#1}}%
\newcommand{\hlprompt}[1]{\textcolor[rgb]{0.2,0.2,0.2}{#1}}%

\usepackage{framed}
\makeatletter
\newenvironment{kframe}{%
 \def\at@end@of@kframe{}%
 \ifinner\ifhmode%
  \def\at@end@of@kframe{\end{minipage}}%
  \begin{minipage}{\columnwidth}%
 \fi\fi%
 \def\FrameCommand##1{\hskip\@totalleftmargin \hskip-\fboxsep
 \colorbox{shadecolor}{##1}\hskip-\fboxsep
     % There is no \\@totalrightmargin, so:
     \hskip-\linewidth \hskip-\@totalleftmargin \hskip\columnwidth}%
 \MakeFramed {\advance\hsize-\width
   \@totalleftmargin\z@ \linewidth\hsize
   \@setminipage}}%
 {\par\unskip\endMakeFramed%
 \at@end@of@kframe}
\makeatother

\definecolor{shadecolor}{rgb}{.97, .97, .97}
\definecolor{messagecolor}{rgb}{0, 0, 0}
\definecolor{warningcolor}{rgb}{1, 0, 1}
\definecolor{errorcolor}{rgb}{1, 0, 0}
\newenvironment{knitrout}{}{} % an empty environment to be redefined in TeX

\usepackage{alltt}
\usepackage{acl2012}
\usepackage{times}
\usepackage{latexsym}
% \usepackage[pdftex]{graphicx}
\usepackage{amsmath}
\usepackage{gb5e}
\usepackage{tikz}
\usetikzlibrary{positioning}
\usepackage{tikz-qtree}
\usepackage{hyperref}
% \usepackage{enumerate}
\usepackage{float}
\usepackage{booktabs}
\usepackage[bottom]{footmisc}
\usepackage[scaled]{beramono}
\usepackage{listings}
\lstset{basicstyle=\ttfamily}

\usepackage[T2A,T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[russian,english]{babel}

\usepackage{natbib}
\bibliographystyle{plainnat}
\bibpunct{(}{)}{,}{a}{,}{,}

\newcommand{\rinline}[1]{SOMETHING WRONG WITH knitr}



\title{Inferring Definiteness from Context}
\author{Christopher Brown\\
University of Texas at Austin\\
\href{mailto:chrisbrown@utexas.edu}{chrisbrown@utexas.edu}}
\date{}

% Final Project
% Due May 10 by 5pm, Informal 1 page proposal due April 8
  % Project report outline
  % Sample publication that resulted from a previous class project.
  % Turn in project code as "cs388-project". See project submission instructions.
% The course information mentions "about 6 to 7 single-spaced pages", a few more would be fine if there are graphics and figures, and this does not include the bibliography.

\begin{document}
\maketitle

\begin{abstract}
\noindent
Noun phrases occurring in natural language can be described as either definite or indefinite.
Definiteness is a semantic concept that relates to givenness, familiarity, topicality, and focus.
It can be denoted by a variety of determiners, the absence of a determiner, or by context.
Focusing on the definiteness markers, \emph{a}/\emph{an} and \emph{the}, this paper investigates what types of models are best at predicting the most suitable determiner when it is not available. This inference is useful in natural language generation and some cases of machine translation.
\end{abstract}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%  PROBLEM AND MOTIVATION  %%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Problem and Motivation} % and Task
Definiteness is an attribute of a noun phrase that describes the nature of its intended referent.
\begin{exe}
  \ex \textbf{A dog} was barking all night. \label{dog:a}
  \ex \textbf{Dogs} were barking all night. \label{dog:plural}
  \ex \textbf{This dog} was barking all night.\footnote{Excluding the deictic sense of \emph{this}.} \label{dog:this}
  \ex \textbf{The dog} was barking all night. \label{dog:the}
\end{exe}
In each case, the bold noun phrase picks out a different set of dogs or implies something different about which dog the speaker means to refer to. \eqref{dog:a} is indefinite; \eqref{dog:plural} is similar, but allows the dogs to take shifts; \eqref{dog:this} suggests the speaker has some way of uniquely identifying the dog, but the hearer would not know which dog without more information; \eqref{dog:the} requires both hearer and speaker to know which dog is referred to.

Definiteness is generally defined as the form of noun phrase that is acceptable when the uniqueness of the referent is known by both speaker and hearer. Specificity differs in that the hearer may not be aware of this uniqueness. Thus \eqref{dog:this} is specific, but not definite; \eqref{dog:the} is definite.

In English, determiners are the primary overt markers of definiteness / indefiniteness.
Definiteness is not completely specified by determiners, though; some uses of \emph{a} can be definite (``A man just proposed to me in the orangery.''\footnote{Fodor and Sag, `Referential and Quantificational Indefinites', \emph{Linguistics and Philosophy} 5. 1982.}); \emph{the} can be indefinite (``After entering the lobby, take the elevator to your left''---even though there may be multiple elevators), while \emph{this} and bare plurals are much more ambiguous. There is a wide variety of other determiners and quantifiers, as well as most pronouns, which mark definiteness in some way.

\subsection{Ubiquity}
Determiners are very common in the English language (Table \ref{tab:browncounts}); like many other functional words, determiners are often redundant---misuse is very quickly detected, and the intended use can usually be determined from context.
\begin{table}
  \centering
  \begin{tabular}{lrr}
    Token & Count & Percentage\\
    \toprule
    \textbf{the} & 69968 & 6.83\% \\
    of & &\\%36449 & 3.56\% \\
    and & &\\%28905 & 2.82\% \\
    to & &\\%26232 & 2.56\% \\
    \textbf{a} & 23490 & 2.29\% \\
    in & &\\%21402 & 2.09\% \\
    \textbf{that} & 10786 & 1.05\% \\
    \dots &       &          \\
    \textbf{this} & 5145 & 0.50\% \\
    \dots &       &          \\
    \textbf{an} & 3746 & 0.36\% \\
  \end{tabular}
  \caption{Brown corpus counts and proportions of selected definiteness markers (in bold).}
  \label{tab:browncounts}
\end{table}

Many studies of definiteness approach the problem via language acquisition; misuse of determiners by learners of languages with definite-marking articles are observed to demonstrate significant patterns, which I discuss later in the section devoted to related work.

\subsection{Simplifying the problem}
I could not find any large corpora annotated for definiteness; \citet{calhoun:2010} describes a corpus where `Information Status' is encoded, but not specifically definiteness. \citet{vieira:2000} developed a corpus of about 1,400 noun phrases annotated with definiteness, but this is relatively small, and the available annotations are relatively deep. I am unaware of any attempts to model definiteness computationally; definiteness is discussed at length in linguistic literature, but its limited usefulness in popular NLP tasks has left it without much empirical / computational attention.

Definiteness effects overlap with other semantic features, particularly presupposition and the scope of context. As with many linguistic aspects of semantics and pragmatics, a complete solution would require a much fuller understanding of language than any current NLP system provides.

In many cases, definiteness is clear from the determiner, as with \emph{a} and \emph{the}. Noun phrases with \emph{a} (and \emph{an}) are predominantly indefinite, and those with \emph{the} are almost always definite. The analysis described in this paper assumes that these particular determiners cover enough cases to serve as a significant portion of the problem, and that \emph{a}/\emph{an} always denote indefiniteness, and \emph{the} always denotes definiteness. The naive baseline starts relatively high; a maximum likelihood estimate using the more common of the two markers (\emph{the}) produces an accuracy of 69.1\%.

This paper demonstrates an approach that achieves up to 79.9\% accuracy using SVM (support vector machines) and a small selection of well-motivated, intuitive features.
I show that it's possible to recover information about definiteness from nearby nouns and similarly shallow features. I do this by replacing all determiners \emph{a}, \emph{an}, and \emph{the} with a special placeholder token, using the original form as the gold label (only distinguishing definite from indefinite).

I compare results of CRF (Conditional Random Field) sequence labeling against a SVM (Support Vector Machine) tagging each token alone.
And, as this is primarily a feature selection problem, and I look at results comparing different subsets of features.







%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  APPLICATIONS  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Applications}
Detecting or inferring definiteness fills a very specific niche of natural language processing. Determiners serve as useful features in POS (Part of Speech) tagging, since they usually mark the beginning of a noun phrase, and in NER (Named Entity Recognition), for the same reason. Such methods regard determiners as a side-effect, though, and don't necessarily distinguish one determiner from another or seek to understand the determiners as independent linguistic features.

This linguistic analysis of understanding determiners at the level of definiteness primarily contributes to two common NLP tasks: language generation and machine translation.



\subsection{Language generation}
When generating language from a logical structure, co-referential noun phrases representing a single entity must surface fluently. It is unnatural to repeat a proper noun or an extended noun phrase when a pronoun would suffice. But context and focus shift as the discourse develops, eventually making any pronoun ambiguous, forcing the speaker to use a more explicit reference. Tracking this throughout a discourse requires understanding the shared information between hearer and speaker, which naturally shifts over time throughout the discourse.

This is often modeled with centering theory---of which there are many variations, but they all involve some kind of stage that only supports or holds a limited number of entities \citep{brennan:1987, grosz:1995, beaver:2000}. When generating natural language from the logical form of a series of events, we must track what alternatives are available at each point, in order to know what level of definiteness is most appropriate, which in turn will determine what sort of noun phrase we use---definite, indefinite, pronoun, etc. Syntactic binding also plays a role here, in determining whether we use a pronoun or a (reflexive) anaphor.

Definiteness is just one part of anaphora generation, and this paper tackles only a partial, but integral, part of the problem. The aspect that is relevant here requires shallower understanding. If we use a full noun phrase more than once, we need to know when to use an indefinite description and when to use the definite form.



\subsection{Machine translation}

Some languages, like Russian and Korean, do not have determiners to denote definiteness; others, like Japanese and Hindi, have a few articles that convey some level of indefiniteness, or are used for other special purposes (such as to denote humans). % that's what the Japanese is doing, right?
When translating from these languages to languages with overt definiteness markers, we must insert determiners that often have no parallel marker in the source text.
There are a few papers discussing this particular problem in machine translation, but they are specific to only a few language pairs \citep{ishikawa:1995, siegel:1996}.

For example, Google Translate renders each of the four alternations of ``A/The man bit a/the dog'' as \foreignlanguage{russian}{Человек укусил собаку.} Translating back into English produces ``A person bitten by a dog.'' Some Russian adjectives mark definiteness, but otherwise, it must be inferred from context or left ambiguous. But translating from Russian into English requires choosing appropriate determiners, for which we need a model of definiteness (in conjunction with a model of anaphora or centering).

\subsection{Other treatment}
These applications are useful to two specific niches of NLP, and apply only in some cases of those areas,
which may explain why so little computational work exists on the subject.
The linguistic and philosophical literature on definiteness is much more developed, but most of the approaches from that area require deep understanding of language. This treatment is outside the scope of this paper, as I focus on shallow features.












%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  EXPERIMENT  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Experiment}
% The basic research question will be to determine what type of language models produce the best prediction of definiteness.
Because English has determiners, every document is `labeled' data. However, because I want to use features deeper than simple surface tokens, I use the WSJ portion of the Penn Treebank (see Table \ref{tab:wsjoverview}).
\begin{table}[H]
  \centering
  \begin{tabular}{r@{$\;\,$}l}
    2,038 & articles \\
    1,027,820 & tokens \\
    77,377 & determiners \\
  \end{tabular}
  \caption{WSJ overview.}
  \label{tab:wsjoverview}
\end{table}
\newcommand\detplaceholder{\guillemotleft\textsc{det}\guillemotright}
To test definiteness inference, I simply replace \emph{a(n)} and \emph{the} with the placeholder \detplaceholder{}, while retaining the original token as the label for that token (collapsing \emph{a} and \emph{an} into one representation). While this is an artificial evaluation metric, it could be useful in both of the application scenarios.

In the language generation case, a noun phrase would surface with a placeholder inserted in determiner position, which could then be resolved by the approach in this paper, using nearby features to infer definiteness. Similarly, in machine translation, noun phrases translated from a determiner-less language to one with determiners could be padded with a placeholder, which would then be resolved by this post-processing step performed on just the target language.

\subsection{Features and Model}
Here are the features that I use, along with the names describing them in the graphs that follow.
\begin{description}
  \item[def na] `NA' if this particular token is not a \detplaceholder{} position.
  \item[def token] Either \detplaceholder{} or the original token. Along with `def na,' this feature is vacuous in the token-wise discrimination case, though useful for the CRF, which labels all tokens.
  \item[next def token] Either \detplaceholder{} or the original token for the position directly following the target position.
  \item[next noun] The next token found in the sequence labeled with one of the Penn Treebank POS tags: NN, NNS, NNP, or NNPS.
  \item[next noun seen] Whether or not the `next noun' occurs earlier in the article.
\end{description}

This is not a typical sequence labeling problem, since relatively few of the tokens need to be resolved.
But each instance of definiteness is not independent of the previous---in fact, a prior mention is a strong indicator that an entity is now in the active context, and that subsequent instances should use the definite determiner. The sequence is crucial in a sense of building and maintaining a `center,' which is a common approach when resolving anaphora.

Most of this sequential aspect of anaphora and shifting context is handled by the preprocessing step. However, I compare using an SVM\footnote{SVM$^{light}$ \citep{joachims:1999} via \href{https://bitbucket.org/wcauchois/pysvmlight}{PySVMLight}. I also tried LaSVM, but results were little better than the baseline.} to using a CRF.\footnote{CRFSuite \citep{CRFsuite}.}
% But with an intelligent set of features, we might achieve sufficient accuracy with a simple logistic regression; given a set of features, evaluate whether the placeholder should be definite or indefinite?
In addition to the learning method, I also compare feature sets, to determine which are the most efficient at predicting the deleted definiteness markers.

\subsection{Results}

In each of the figures below, I have drawn the baseline as a horizontal line at 69.1\% for simplicity; realistically, it would vary slightly across different cross-fold validation samples of the corpus.

I have sampled results for each of the following total counts of articles: 100, 250, 500, 1000, 2038 (the maximum). Each result reported is for a random shuffling of articles (in the CRF case) or tokens (in the SVM case), using a train / test split of 90\% / 10\%.

The legend in each plot describes different subsets of my feature functions. Most of these follow a pattern of incremental inclusion of features, see Figure \ref{fig:features} for the full hierarchy (each node includes all of its parents' features).

\begin{figure}
  \centering
  \begin{tikzpicture}
    \tikzset{edge from parent/.style={draw,-latex}}
    \Tree
    [.{def na}
      [.\node(deftoken){def token};
        \node(nextdef){next def};
        [.{next noun}
          \node(nextnounseen){next noun seen};
        ]
      ]
    ]
    \node[below=of deftoken,yshift=-.66in](full){full};
    \draw[-latex] (nextdef) -- (full);
    \draw[-latex] (nextnounseen) -- (full);
  \end{tikzpicture}
  \caption{Hierarchy of inclusion of features in experimental feature sets.}\label{fig:features}
\end{figure}

SVM results use a polynomial kernel. The first plot below shows that a polynomial kernel consistently performs better than alternative kernels; the accuracy lines depict results using the full feature set (see Figure \ref{fig:svmkernel}).

\begin{figure}
\begin{knitrout}\small
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}

{\centering \includegraphics[width=\linewidth]{knitr-fig/latex-svm_kernel} 

}



\end{knitrout}

  \caption{Comparison of SVM kernels.}\label{fig:svmkernel}
\end{figure}

The full feature set consistently performs the highest (see Figure \ref{fig:svmffs}). Differences between the next token and the next noun (which are often equivalent) are small; this is somewhat surprising, the next token is an easier metric but seems to do just as well or better. Searching the text of the article for the previous occurrences of the target noun does not seem to add any significant gain.

\begin{figure}
\begin{knitrout}\small
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}

{\centering \includegraphics[width=\linewidth]{knitr-fig/latex-svm_ffs} 

}



\end{knitrout}

  \caption{Comparison of feature sets for SVM.}\label{fig:svmffs}
\end{figure}


The CRF offered no benefit, though we see mostly the same pattern in trade-offs between more complex features sets (see Figure \ref{fig:crfffs}).
The SVM seems better suited to the problem, and its results are a few percentage points higher, on average.

\begin{figure}
\begin{knitrout}\small
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}

{\centering \includegraphics[width=\linewidth]{knitr-fig/latex-crf_ffs} 

}



\end{knitrout}

  \caption{Comparison of feature sets for CRF.}\label{fig:crfffs}
\end{figure}

Notably, though, the CRF and the SVM ran in comparable time, despite the CRF also providing vacuous tags for all non-\detplaceholder{} tokens.

These results demonstrate that it is relatively simple to increase accurate inference of definiteness on this pair of definite-marking articles.

% \section{Semantics of definiteness}
% The theoretical semantics of definite noun phrases has an extensive history; we can start with Gottlob Frege and Bertrand Russell and names. Frege said that the meaning of a name (or definite noun phrase) was the object denoted by that description. Russell complicated matters with his ``The King of France is bald'' example, in which ``the King of France'' cannot refer to anything (at least not since 1848). Russell would call this sentence false, despite the description's failure to refer to anything; the failure of the noun phrase propagates out to the failure of the sentence.

% Keith Donnellan and P. F. Strawson disagree; they say that referencing is something speakers, not words, do, and that ``the King of France'' is simply unsuccessful.
% Compare ``a King of France is bald,'' which can refer to any (dead) past King of France, and thus have a truth value. Definite noun phrase usually denote a unique entity, and if this fails, the sentence is incoherent. But compare ``After you enter the lobby, take the elevator to the 13th floor,'' which is acceptable even if there is more than one elevator.
% % Donnellan differentiates between attributive and referential uses of definite noun phrases, but that's not important here.

% This is just the beginning, but it's clear that the difference between definite and indefinite noun phrases involves a number of factors, such as context, real world knowledge, and other pragmatic phenomena. It is an active field of study in linguistics or philosophy of language, but has received very little attention in computational linguistics.




\section{Related work}

\citet{progovac:1995} begins with the radical syntactic change that \citet{abney:1987} had recently proposed: that noun phrases are headed by the determiner, not the noun. She demonstrates, using the position of pronouns and other demonstratives, that Serbian-Croatian (a language without articles like \emph{a/the}) has a determiner position, and that it is usually filled by a null determiner of some definiteness. In Serbian-Croatian, there is a definiteness marker \emph{-i}, which Progovac explains as arising in determiner position, but transferring to the adjective on the surface.

\citet{ko:2009} uses L2-acquisition errors to demonstrate definiteness effects via determiner usage. They distinguish `definiteness' and `specificity' by stating that `definiteness' involves common knowledge of uniqueness of referent between speaker and hearer, while `specificity' only involves that uniqueness be known to the speaker. Native Korean and Russian speakers (both article-less languages) demonstrated, via a task very similar to the one described in this paper, that speakers tend to associate two articles, like \emph{a} and \emph{the}, with the value of one of these features, either [$\pm$definite] (correct, for English) or [$\pm$specific] (incorrect). Given some larger context and a placeholder in determiner position, the task is to replace the placeholder with either \emph{the}, \emph{a}, or a blank. While my task does not consider the null determiner option, this experimental design lends credibility to my peculiar and somewhat artificial task.

Similarly, \citet{cho:2011} looks for evidence of a determiner phrase in Russian, in native English learners' acquisition of Russian. Based on patterns of these speakers using certain definiteness-marking adjectives (with `covertly expressed' definite features), she claims that the English grammar of definiteness is readily transferred to definiteness features in Russian.

\citet{vieira:2000} uses a portion of the Penn Treebank containing about 1,400 definite descriptions, based on annotations gathered from multiple annotations produced by their subject pool (this was partly to determine how easy / reliable the task itself was, which they investigate further in \citet{poesio:1998}). They primarily had the purpose of distinguishing discourse-old and discourse-new descriptions; while they call their system shallow, it uses much more descriptive features than mine, using aspects such as copular constructions, specific predicates, like factives, restrictive / non-restrictive post-modification, appositivity, bridging features and and NER. Their prediction model is a decision tree based on these features, and their F-score on the test data set (400 of the 1,400 descriptions) was 0.69.

\subsection{Definiteness across translation}

\citet{siegel:1996} addresses the specific problem of Japanese to German machine translation, focusing on Japanese features that are not manifested at surface level.
German determiners like \emph{ein} and \emph{dem} do not align to anything in the source Japanese sentences, but they are required in the German translation. Siegel derives Prolog transfer rules for inserting appropriate determiners in the German sentence output.

Siegel claims that this process requires more than just post-processing output in the target language, and that several factors affect the choice of determiners in the German. For her, the problem is `interlingual,' and must be addressed at the level of translation.
However, as most modern translation systems have shown, techniques ignoring theoretical complexities often surpass more linguistically correct systems.
% To solve these issues at the level of translation is very specialized
% Siegel's methodology is highly domain specific; not only are the rules she proposes specific to translating from Japanese to German, but even these are tuned for the translated informal conversation corpus that she discusses.

% Other approaches have included pre-processing Japanese text for relevant markers, inferring definiteness and number at the source language level.
% Siegel claims this is too shallow. For example, \emph{shain} (staff member) can translate to either \emph{die Mitarbeiter} (the staff-members) or \emph{der Mitarbeiter} (the staff-member), and this is `dependent on the domain.'
% Her rules use other definiteness signals in the source language (Japanese), like numerals.
% Using a combination of preference rules with defaults, handles translating several types of Japanese noun phrases into German, inserting number and definiteness markers that are not given in the Japanese source sentences.
% Many more languages than Japanese lack determiners; many more than German have them. It would be preferable to start with research considering the problem at a more general level. The rules she proposes may have correlates in other language pairs; I don't know how transferable these transfer rules are, but their lexical specificity suggests that even if the rules would be similar for, say, English, they are not general enough to extended across languages automatically.
% Siegel does not demonstrate that her transfer rules are better at translating than simpler pre- or post-processing rules. This research is very early in machine translation, before the statistical revolution, but she relies on intuition rather than results.
% My project investigates how much can be achieved via non-aligned surface-level models. It is not only a translation problem, but one aspect of semantics which has a major application in translation, particularly by improving post-processing of the translation system's output. Comparing this to a baseline, my approach could itself become a baseline for claims like Siegel's, since I address just one of the three factors that Siegel claims this problem depends on. If her approach does significantly better than the post-processing of my model, that would be substantial support for her claim of interlingual dependence, and justify further research into inferring definiteness placeholders on the source language, so that they can be translated.
% I'm investigating the recoverability of definiteness markers at the surface level---on the target language, in a translation scenario. This is more general; whereas language pairs are quadratic in the number of languages handled by the translation system, and translation between them requires a large number of parallel texts, surface-level post-processing depends only on the target language and does not require the same depth of annotation. This means much more data can be put to use, more easily.

\section{Limitations and future work}
Currently, this system uses POS tags provided with the corpus as features in the training as well as the testing phase. As previously mentioned, determiners are useful features in POS tagging, so this inter-dependence could potentially become a catch-22. However, I think that the difference between \emph{a}/\emph{an} and \emph{the} should not be too egregious an issue for a POS tagger; I expect that a POS tagger trained on a corpus with anonymized determiners would learn to use the merged placeholder \detplaceholder{} just as well.

A bigger issue is that \emph{a} and \emph{the} are blindly used as indicators of definiteness. While the corpus developed in \citet{vieira:2000} is relatively small, their approach suggests that some measure of definiteness / specificity could be induced from crowd-sourced annotations. Active learning could be used to label the less ambiguous determiners (like \emph{the}, \emph{that}), leaving definiteness annotations of more ambiguous determiners and quantifiers (like \emph{a}, \emph{this}, \emph{some}) to human judges.

\section{Conclusion}
For this task of collapsing \emph{a}/\emph{an} and \emph{the} into a single token and then predicting the original identity, I have shown that an SVM (or CRF) can significantly improve upon the baseline by using a small and simple set of features. This approach is promising as part of the foundation of a larger language generation system, though such a system's requirements span far wider than the narrow issue developed here. However, I think that more linguistically justifiable approaches to problems can offer improvements to current solutions, even if the methodology is much more simple than its theoretical basis.

Implementing this, or some part of this approach, in a language generation system will be a much more accurate test of its worth, but I believe that any improvement in making generated language sound more natural is worthwhile. This paper shows that some aspect of definiteness is encoded in very simple features, which, if factored into the generation process, will help to determine what type of noun phrase is most appropriate.



\section*{Appendix}

Code written to perform the analyses in this project is available at \href{https://github.com/chbrown/nlp}{github.com/chbrown/nlp}. See the \texttt{python/det} subfolder in particular.

This document is licensed \href{http://creativecommons.org/licenses/by/3.0/}{CC BY 3.0}, \copyright{} 2013 Christopher Brown.

\bibliography{/Users/chbrown/Dropbox/ut/tex/liography}

\end{document}


# SVMs
SVMlight = pysvmlight
  =? http://tfinley.net/software/svmpython2/
SVMSGD - http://leon.bottou.org/projects/sgd
Pegasos - slow - http://www.cs.huji.ac.il/~shais/code/index.html
LaSVM - http://leon.bottou.org/projects/lasvm - about same as svm light to train, relatively slow to test, about 10 percentage points lower accuracy than linear SVM.
VowpalWabbit - http://hunch.net/~vw/
Liblinear - related to LIBSVM - http://www.csie.ntu.edu.tw/~cjlin/liblinear/
LIBSVM
Sofia-ml - http://code.google.com/p/sofia-ml/
TinySVM - ??? - http://chasen.org/~taku/software/TinySVM/
scikit-learn
  http://scikit-learn.sourceforge.net/ml-benchmarks/
  http://scikit-learn.org/stable/

Matrix decomposition in Java: http://code.google.com/p/decomposer/

% LaSVM:
% la test
% loading model: 49246 svs
% examples: 7738   features: 13268
% accuracy= 69.2815 (5361/7738)
