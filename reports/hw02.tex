\documentclass[10pt]{article}\usepackage{graphicx, color}
%% maxwidth is the original width if it is less than linewidth
%% otherwise use linewidth (to make sure the graphics do not exceed the margin)
\makeatletter
\def\maxwidth{ %
  \ifdim\Gin@nat@width>\linewidth
    \linewidth
  \else
    \Gin@nat@width
  \fi
}
\makeatother

\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\definecolor{fgcolor}{rgb}{0.2, 0.2, 0.2}
\newcommand{\hlnumber}[1]{\textcolor[rgb]{0,0,0}{#1}}%
\newcommand{\hlfunctioncall}[1]{\textcolor[rgb]{0.501960784313725,0,0.329411764705882}{\textbf{#1}}}%
\newcommand{\hlstring}[1]{\textcolor[rgb]{0.6,0.6,1}{#1}}%
\newcommand{\hlkeyword}[1]{\textcolor[rgb]{0,0,0}{\textbf{#1}}}%
\newcommand{\hlargument}[1]{\textcolor[rgb]{0.690196078431373,0.250980392156863,0.0196078431372549}{#1}}%
\newcommand{\hlcomment}[1]{\textcolor[rgb]{0.180392156862745,0.6,0.341176470588235}{#1}}%
\newcommand{\hlroxygencomment}[1]{\textcolor[rgb]{0.43921568627451,0.47843137254902,0.701960784313725}{#1}}%
\newcommand{\hlformalargs}[1]{\textcolor[rgb]{0.690196078431373,0.250980392156863,0.0196078431372549}{#1}}%
\newcommand{\hleqformalargs}[1]{\textcolor[rgb]{0.690196078431373,0.250980392156863,0.0196078431372549}{#1}}%
\newcommand{\hlassignement}[1]{\textcolor[rgb]{0,0,0}{\textbf{#1}}}%
\newcommand{\hlpackage}[1]{\textcolor[rgb]{0.588235294117647,0.709803921568627,0.145098039215686}{#1}}%
\newcommand{\hlslot}[1]{\textit{#1}}%
\newcommand{\hlsymbol}[1]{\textcolor[rgb]{0,0,0}{#1}}%
\newcommand{\hlprompt}[1]{\textcolor[rgb]{0.2,0.2,0.2}{#1}}%

\usepackage{framed}
\makeatletter
\newenvironment{kframe}{%
 \def\at@end@of@kframe{}%
 \ifinner\ifhmode%
  \def\at@end@of@kframe{\end{minipage}}%
  \begin{minipage}{\columnwidth}%
 \fi\fi%
 \def\FrameCommand##1{\hskip\@totalleftmargin \hskip-\fboxsep
 \colorbox{shadecolor}{##1}\hskip-\fboxsep
     % There is no \\@totalrightmargin, so:
     \hskip-\linewidth \hskip-\@totalleftmargin \hskip\columnwidth}%
 \MakeFramed {\advance\hsize-\width
   \@totalleftmargin\z@ \linewidth\hsize
   \@setminipage}}%
 {\par\unskip\endMakeFramed%
 \at@end@of@kframe}
\makeatother

\definecolor{shadecolor}{rgb}{.97, .97, .97}
\definecolor{messagecolor}{rgb}{0, 0, 0}
\definecolor{warningcolor}{rgb}{1, 0, 1}
\definecolor{errorcolor}{rgb}{1, 0, 0}
\newenvironment{knitrout}{}{} % an empty environment to be redefined in TeX

\usepackage{alltt}
%\usepackage[pdftex]{graphicx}
%\usepackage{graphicx}

\usepackage{henrian-basic}
\usepackage{henrian-homework}

\newcommand{\rinline}[1]{SOMETHING WRONG WITH KNITR}



\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{subfig}
\usepackage{hyperref}
\usepackage{enumerate}
\usepackage{cancel}
\usepackage{float}
\usepackage{booktabs}
\usepackage[bottom]{footmisc}

\usepackage{beramono}
\usepackage{listings}
\lstset{basicstyle=\ttfamily}

\usepackage{natbib}
\bibliographystyle{plainnat}
\bibpunct{(}{)}{,}{a}{,}{,}

\makeHeaders{NLP: Homework 2}

\begin{document}

\section{Part-of-Speech Tagging}

Bags-of-words and n-grams are very simple language models.
Part-of-speech (POS) models are the next step in terms of complexity.
These models assume that each token in a sequence of natural language is paired with one of a relatively small set of POS tags.

\subsection{HMMs and CRFs}

We'll compare two methods for inferring POS tag sequences.

\begin{description}
  \item[Hidden Markov Model] HMMs can be used as a generative model of any system of discrete, linear symbols, such as language. An HMM usually takes a sequence of observed output symbols, like tokens of language, and infers the underlying states that `produced' each symbol, which correspond to the POS tags. It models the full joint distribution of labels and observations. This means it can also infer the most likely tokens (output), given a sequence of tags, but this is not a very useful task when dealing with language.
  \item[Conditional Random Fields] CRFs are a more recently developed alternative to the HMM approach. CRFs are discriminative models---they only model the conditional probability of labels, e.g., POS tags, given a sequence of tokens. CRFs do not perform exact inference; they are basically a combination of logistic regressions whose parameters are learned via Maximum Likelihood estimation, via an optimization method such as L-BFGS (Limited-memory Broyden-Fletcher-Goldfarb-Shanno).
\end{description}

\noindent
HMMs can be trained easily and quickly using dynamic programming. Multiple iterations are unnecessary, and a convergence criterion does not need to be specified. However, they are not as accurate as CRFs, because they are not optimized for the label (POS tag) inference task. HMMs are not easily extended to handle multiple features, while that is trivial for CRFs.

There is a trade-off between training time and accuracy. CRFs take considerably longer to train, but they are more accurate.

The results for a series of comparisons between Mallet's\footnote{MALLET: A Machine Learning for Language Toolkit. \url{http://mallet.cs.umass.edu}} CRF and HMM implementations are show below in Table \ref{table:1}.




\begin{table}[H]
  \centering
  \begin{tabular}{lllllr}
    Model & Corpus & Training accuracy & Testing accuracy & OOV-only & Time (seconds) \\
    \midrule
    HMM   & Atis & 0.888 & 0.865 &
      0.180 & 2.987 \\
    CRF   & Atis & 0.999 & 0.928 &
      0.273 & 84.971 \\
    CRF+ & Atis & 0.999 & 0.940 &
      0.440 & 84.570 \\
    \midrule
    HMM   & WSJ & 0.862 & 0.785 &
      0.379 & 51.304 \\
    CRF   & WSJ & 0.951 & 0.752 &
      0.431 & 2795.950 \\
    CRF+ & WSJ & 0.992 & 0.862 &
      0.626 & 5608.262 \\
  \end{tabular}
  \caption{`CRF+' refers to the CRF with additional word-property features; `OOV-only' refers to accuracy on out-of-vocabulary items in the held-out test data. Each accuracy measure is the ratio of correctly labeled tokens to all tokens for that model and corpus.\\
  ATIS refers to a corpus of conversations related to airline reservation; each figure in those rows is the average over a 10-fold train/test split, training on 80\% of the data and testing on the remaining 20\%. WSJ refers to the Wall Street Journal; the models were trained on section 00 and tested on section 01.}
  \label{table:1}
\end{table}
The CRF almost unilaterally beats the HMM in both the very constrained corpus (ATIS) and a more diverse corpus (WSJ). While the results are not state-of-the-art, they clearly indicate the big differences between the HMM and CRF.
The WSJ HMM happens to beat the CRF in testing data accuracy, but CRF performance in the current configuration varies markedly. Over the 10-fold evaluation of the ATIS data, the CRF test accuracy ranges between 90.6\% and 94.2\%, nearly four percentage points.
A more robust CRF implementation would likely run more iterations and have less variable results.

As we might expect, test accuracy among only out-of-vocabulary (OOV) items is much worse than among in-vocabulary tokens. The CRF is a consistent winner in this task, demonstrating an advantage of the discriminative model. The HMM struggles with OOV tokens, since it models the joint distribution of both labels and tokens, and it has never seen these tokens before. The CRF results leave much room for improvement, but the CRF is much better tuned to solving the problem of inferring POS tags for OOV tokens.

The HMM is not quite as prone to over-fitting as the CRF. The CRF has astounding test accuracy results, particularly on the smaller data set. Therefore, the difference between training and testing performance, for the CRF, is much more pronounced. I don't think this has much to say in terms of advantages or disadvantages of one model over the other, but just shows how crucial it is to have a test dataset.

The largest difference between the HMM and CRF models is the training time required. Due to the complex optimizations that the CRF has to perform in inferring its parameters, it takes between 20 and 100 times longer to train. Whether or not this is a major consideration depends on the application. I imagine that in most cases, the increase in accuracy is well worth a couple orders of magnitude more compute time, even if the increased accuracy is disproportionately small compared to the increased training time. Like testing accuracy, this too has a lot of variability, in part due to other jobs running on the same machine, or differences in processing power between each machine.


Adding binary morphological features significantly increases accuracy. The CRF+ model above differed from the CRF model only in terms of the additional features, but it performed remarkably better. The features I added were:
\begin{description}
  \item[GERUND] Ends in `ing'
  \item[PLURAL] Ends in `s'
  \item[SHORT] Less than four characters
  \item[UPPER] Starts with an uppercase character
\end{description}
These features mark a lot of false positives as PLURAL or GERUND, but they still help increase accuracy, particularly on OOV items.

On just the ATIS corpus, I observed short 5-fold runs of the model on two subsets of these features, GERUND+PLURAL and SHORT+UPPER, i.e., morphological vs. orthographical. The difference in test accuracy for the different combinations was negligible (0.938 vs. 0.937, respectively), but the morphological features were far more beneficial in OOV accuracy (0.370 vs. 0.216). The effect that a few simple extra features has on accuracy suggests that adding more might be very helpful. With this small, variable sample, it's hard to make strong claims about training times, but the time difference between training token features and tokens plus extra features does not seem significant.

\subsection{Reversed Model}

My extension to the established model was to run the same experiment, but after reversing each sentence, as in the first part of the first homework.
%I don't align two HMMs, backwards and forwards, and linearly interpolate their predictions; that would require much more
Because the HMM is a directed model and the CRF is a form of a Markov Random Field (MRF), which is not directed, we might expect to see differences between the `forward' HMM and the `backward' HMM, but no differences in the CRF performance.




\begin{table}[H]
  \centering
  \begin{tabular}{lllllr}
    Model & Corpus & Training accuracy & Testing accuracy & OOV-only & Time (seconds) \\
    \midrule
    HMM   & Atis & 0.901 & 0.882 &
      0.197 & 5.594 \\
    CRF   & Atis & 0.998 & 0.929 &
      0.313 & 85.081 \\
    CRF+ & Atis & 0.999 & 0.942 &
      0.462 & 83.374 \\
    \midrule
    HMM   & WSJ & 0.863 & 0.785 &
      0.383 & 87.367 \\
    CRF   & WSJ & 0.996 & 0.811 &
      0.480 & 6377.220 \\
    CRF+ & WSJ & 0.994 & 0.874 &
      0.620 & 5782.205 \\
  \end{tabular}
  \caption{Exactly the same figures as before, but all after reversing each input sentence string.}
  \label{table:2}
\end{table}
However, the results are practically indistinguishable from those in the first table. This doesn't say so much about the directionality, I think; we saw the same effect in the first homework's experiment where we got identical results for both forward and backward models, as long as we left out the sentence boundaries.

\subsection{Instructions}

Again, all code, with full SBT project, is available at:
\begin{lstlisting}
  git clone https://github.com/chbrown/nlp.git
\end{lstlisting}
Commands used to run the code can be found in `hw02.README'.

\end{document}

cross:
  corpus:     wsj / atis
  model:      crf / hmm
  features:   with ortho / normal / only ortho

measurements:
  run time
  variables
  oov:        all / only oov
  train/test: train / both

Report

Your report should contain a problem statement, the approach that you took to solve the problem, a brief discussion of the experiments you ran, including a nicely formatted table(s) of results, with training and test accuracy (both overall and just for OOV items), number of OOV items as a percentage of total test tokens, and run time for each approach for each corpus. Also include a discussion of your results that answers at least the following questions, where possible, explaining the results in terms of underlying algorithmic properties.
1. How does the overall test accuracy of CRF and HMM differ (when using only tokens) and why?
2. How does the test accuracy for OOV items for CRF and HMM differ (when using only tokens) and why?
3. How does the training accuracy of HMM and CRF differ and why?
4. How does the run time of HMM and CRF differ and why?
5. How does adding orthographic features affect the accuracy (both overall and OOV) and runtime of the CRF and why?
Which features helped the most? (i.e. try only including some feature types and not others)
If you are ambitious and have time, you might try adding additional types of features of your own design and discuss your results.

